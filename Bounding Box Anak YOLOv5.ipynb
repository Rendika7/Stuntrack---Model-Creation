{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"13EwQ4zf99R_Hdwu0WVjk6-Cd5Frz8NIN","authorship_tag":"ABX9TyNEcs/cTNXn+UH1G1Usz4Np"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install --upgrade pillow"],"metadata":{"id":"dbEDVeR-vDVg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705381236976,"user_tz":-420,"elapsed":2839,"user":{"displayName":"RENDIKA NURHARTANTO","userId":"08654841777874618172"}},"outputId":"3ff633c5-8aa4-4393-b9eb-c878cf569bba"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (10.2.0)\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3108, in _dep_map\n","    return self.__dep_map\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2901, in __getattr__\n","    raise AttributeError(attr)\n","AttributeError: _DistInfoDistribution__dep_map\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n","    status = run_func(*args)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in wrapper\n","    return func(self, options, args)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 441, in run\n","    conflicts = self._determine_conflicts(to_install)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 572, in _determine_conflicts\n","    return check_install_conflicts(to_install)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n","    package_set, _ = create_package_set_from_installed()\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n","    dependencies = list(dist.iter_dependencies())\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/metadata/pkg_resources.py\", line 216, in iter_dependencies\n","    return self._dist.requires(extras)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2821, in requires\n","    dm = self._dep_map\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3110, in _dep_map\n","    self.__dep_map = self._compute_dependencies()\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3120, in _compute_dependencies\n","    reqs.extend(parse_requirements(req))\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3173, in __init__\n","    super(Requirement, self).__init__(requirement_string)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/requirements.py\", line 102, in __init__\n","    req = REQUIREMENT.parseString(requirement_string)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 1131, in parse_string\n","    loc, tokens = self._parse(instring, 0)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n","    loc, exprtokens = e._parse(instring, loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n","    return e._parse(\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n","    loc, exprtokens = e._parse(instring, loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4959, in parseImpl\n","    loc, tokens = self_expr._parse(instring, loc, doActions, callPreParse=False)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n","    loc, exprtokens = e._parse(instring, loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n","    loc, exprtokens = e._parse(instring, loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 5226, in parseImpl\n","    return super().parseImpl(instring, loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4375, in parseImpl\n","    return self.expr._parse(instring, loc, doActions, callPreParse=False)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3864, in parseImpl\n","    loc, resultlist = self.exprs[0]._parse(\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n","    return e._parse(\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4375, in parseImpl\n","    return self.expr._parse(instring, loc, doActions, callPreParse=False)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3864, in parseImpl\n","    loc, resultlist = self.exprs[0]._parse(\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n","    return e._parse(\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n","    return e._parse(\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 811, in _parseNoCache\n","    pre_loc = self.preParse(instring, loc)\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1732, in isEnabledFor\n","    return self._cache[level]\n","KeyError: 50\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/pip3\", line 8, in <module>\n","    sys.exit(main())\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n","    return command.main(cmd_args)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n","    return self._main(args)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n","    return run(options, args)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 206, in exc_logging_wrapper\n","    logger.critical(\"Operation cancelled by user\")\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1523, in critical\n","    if self.isEnabledFor(CRITICAL):\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1734, in isEnabledFor\n","    _acquireLock()\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 226, in _acquireLock\n","    _lock.acquire()\n","KeyboardInterrupt\n","^C\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"D7RgHIdesWDF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705382276932,"user_tz":-420,"elapsed":238960,"user":{"displayName":"RENDIKA NURHARTANTO","userId":"08654841777874618172"}},"outputId":"fdced96d-ad91-4a1a-8001-a7a267c1a1a7"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!git init\n","!git config --global user.email \"rendikarendi96@gmail.com\"\n","!git config --global user.name \"Rendika7\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vd5vb7FntLwW","executionInfo":{"status":"ok","timestamp":1705383321625,"user_tz":-420,"elapsed":696,"user":{"displayName":"RENDIKA NURHARTANTO","userId":"08654841777874618172"}},"outputId":"59fe829f-86dc-46fa-cf1e-e16d29c101fc"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mhint: Using 'master' as the name for the initial branch. This default branch name\u001b[m\n","\u001b[33mhint: is subject to change. To configure the initial branch name to use in all\u001b[m\n","\u001b[33mhint: of your new repositories, which will suppress this warning, call:\u001b[m\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint: \tgit config --global init.defaultBranch <name>\u001b[m\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\u001b[m\n","\u001b[33mhint: 'development'. The just-created branch can be renamed via this command:\u001b[m\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint: \tgit branch -m <name>\u001b[m\n","Initialized empty Git repository in /content/.git/\n"]}]},{"cell_type":"code","source":["!ls \"/content/drive/MyDrive/Colab Notebooks/Stuntrack\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"44w2MRR2xwQa","executionInfo":{"status":"ok","timestamp":1705383568104,"user_tz":-420,"elapsed":7,"user":{"displayName":"RENDIKA NURHARTANTO","userId":"08654841777874618172"}},"outputId":"958117de-a11e-4f67-b1a3-12b39d7f8893"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["'Boundingbox Anak.ipynb'\t   DeepLearning_Yohanes.ipynb\n","'Bounding Box Anak YOLOv5.ipynb'  'Hasil Model'\n","'Data Final'\t\t\t  'Image Stunting Prediction.ipynb'\n","'Data Test'\t\t\t  'Introduction to Computer Vision.ipynb'\n","'Data Train'\t\t\t   The_Hello_World_of_Neural_Network_with_TensorFlow.ipynb\n","'Data Validation'\t\t   yolov3.weights\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"0l3D3FR5xwST"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","from PIL import Image\n","import cv2\n","import torch\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import os, os.path\n","from PIL import Image\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import time\n","import numpy as np\n","from google.colab import files\n","import keras.utils as image\n","import random\n","import shutil\n","from keras.preprocessing import image\n","from google.colab.patches import cv2_imshow"],"metadata":{"id":"NBe0J8kwoEyf","executionInfo":{"status":"aborted","timestamp":1705381234160,"user_tz":-420,"elapsed":3,"user":{"displayName":"RENDIKA NURHARTANTO","userId":"08654841777874618172"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Detection part\n"],"metadata":{"id":"PxdMMoPL--Mm"}},{"cell_type":"markdown","source":["# import pretrained Model Yolov5S"],"metadata":{"id":"YLBNuGOn5EII"}},{"cell_type":"code","source":["model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n","device = torch.device(\n","    'cuda') if torch.cuda.is_available() else torch.device('cpu')\n","model.to(device).eval()"],"metadata":{"id":"E6Xh6WM6nHc2","executionInfo":{"status":"aborted","timestamp":1705381234162,"user_tz":-420,"elapsed":4,"user":{"displayName":"RENDIKA NURHARTANTO","userId":"08654841777874618172"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Detect People Function"],"metadata":{"id":"zOR19xhJ5XDq"}},{"cell_type":"code","source":["def detect_people(image):\n","    img = Image.fromarray(image)\n","    img = img.convert('RGB')\n","    # img = img.resize((640, 640))\n","    results = model(img)\n","    detections = results.xyxy[0]\n","    # Filter only people (class index 0)\n","    detections = detections[detections[:, 5] == 0]\n","    return detections"],"metadata":{"id":"W-F1p408SfT3","executionInfo":{"status":"aborted","timestamp":1705381234174,"user_tz":-420,"elapsed":16,"user":{"displayName":"RENDIKA NURHARTANTO","userId":"08654841777874618172"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Assign Dataset_Root and get each image file name"],"metadata":{"id":"8gC3-xsh5eKy"}},{"cell_type":"code","source":["DATASET_ROOT = \"/content/drive/MyDrive/Colab Notebooks/Stuntrack/Data Final/Stunting\"\n","\n","image_path = os.listdir(DATASET_ROOT)\n","\n","jpg_files = [file for file in image_path if file.endswith(\".jpg\")]\n","print(jpg_files)\n","len(jpg_files)"],"metadata":{"id":"jDxOzX5aSgHS","executionInfo":{"status":"aborted","timestamp":1705381234175,"user_tz":-420,"elapsed":17,"user":{"displayName":"RENDIKA NURHARTANTO","userId":"08654841777874618172"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Manual Rotation Testing"],"metadata":{"id":"SXnsJxjk40wJ"}},{"cell_type":"code","source":["# Load the image\n","image_path = \"/content/drive/MyDrive/Colab Notebooks/Stuntrack/Data Final/Stunting/TB_Fatar.jpg\"\n","image = cv2.imread(image_path)\n","\n","rotated_image = cv2.rotate(image, cv2.ROTATE_180)\n","\n","# Detect people\n","detections = detect_people(rotated_image)\n","print(detections)\n","\n","# Extract bounding box coordinates and confidence\n","xmin, ymin, xmax, ymax, confidence, _ = detections[0][:6]\n","print(\"Confidence:\", confidence)\n","\n","# Draw bounding box on the image\n","cv2.rectangle(rotated_image, (int(xmin), int(ymin)), (int(xmax), int(ymax)), (0, 0, 255), 5)\n","\n","# Display the image\n","cv2_imshow(rotated_image)"],"metadata":{"id":"6xHI6o3lqpsO","executionInfo":{"status":"aborted","timestamp":1705381234178,"user_tz":-420,"elapsed":20,"user":{"displayName":"RENDIKA NURHARTANTO","userId":"08654841777874618172"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Auto Detect People in Every Rotation for Single Image"],"metadata":{"id":"GAfFmw9S-mAa"}},{"cell_type":"code","source":["# Load the original image\n","image_path = \"/content/drive/MyDrive/Colab Notebooks/Stuntrack/Data Final/Stunting/TB_Fatar.jpg\"\n","original_image = cv2.imread(image_path)\n","\n","# List to store results for each rotation\n","results_per_rotation = []\n","\n","# Define the rotation angles\n","rotation_angles = [0, 90, 180, 270]\n","\n","# Iterate through each rotation angle\n","for angle in rotation_angles:\n","    if angle == 90:\n","        # Rotate the image\n","        rotated_image = cv2.rotate(original_image, cv2.ROTATE_90_CLOCKWISE)\n","    elif angle == 180:\n","        # Rotate the image\n","        rotated_image = cv2.rotate(original_image, cv2.ROTATE_180)\n","    elif angle == 270:\n","        # Rotate the image\n","        rotated_image = cv2.rotate(original_image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n","    else:\n","        # Rotate the image for other angles\n","        rotated_image = cv2.rotate(original_image, angle)\n","\n","    # Detect people in the rotated image\n","    detections = detect_people(rotated_image)\n","\n","    # Check if detections is not None and not empty\n","    if detections is not None and len(detections) > 0:\n","        # Iterate through all detected bounding boxes\n","        for detection in detections:\n","            # Extract bounding box coordinates and confidence\n","            xmin, ymin, xmax, ymax, confidence, _ = detection[:6]\n","\n","            # Store the results for this rotation\n","            results_per_rotation.append({\n","                'angle': angle,\n","                'confidence': confidence,\n","                'roi': (int(xmin), int(ymin), int(xmax), int(ymax))\n","            })"],"metadata":{"id":"honMacGz6AfV","executionInfo":{"status":"aborted","timestamp":1705381234179,"user_tz":-420,"elapsed":21,"user":{"displayName":"RENDIKA NURHARTANTO","userId":"08654841777874618172"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results_per_rotation"],"metadata":{"id":"GQrsqiP077us","executionInfo":{"status":"aborted","timestamp":1705381234179,"user_tz":-420,"elapsed":21,"user":{"displayName":"RENDIKA NURHARTANTO","userId":"08654841777874618172"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Find the rotation with the highest confidence\n","best_rotation_result = max(results_per_rotation, key=lambda x: x['confidence'])\n","\n","# Get the best ROI and confidence\n","best_roi = best_rotation_result['roi']\n","best_confidence = best_rotation_result['confidence']\n","\n","# Draw bounding box on the original image using the best ROI\n","cv2.rectangle(original_image, (best_roi[0], best_roi[1]), (best_roi[2], best_roi[3]), (0, 0, 255), 5)\n","\n","# Display the original image with the best ROI\n","cv2_imshow(original_image)"],"metadata":{"id":"eRfKHAsx6tLJ","executionInfo":{"status":"aborted","timestamp":1705381234180,"user_tz":-420,"elapsed":22,"user":{"displayName":"RENDIKA NURHARTANTO","userId":"08654841777874618172"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","Dalam tensor `[3.64248e+02, 4.40524e+02, 2.39838e+03, 4.44644e+03, 3.08422e-01, 0.00000e+00]`, nilai-nilai tersebut dapat diartikan sebagai berikut:\n","\n","- x (koordinat x atas kiri bounding box): 3.64248e+02\n","- y (koordinat y atas kiri bounding box): 4.40524e+02\n","- lebar bounding box: 2.39838e+03\n","- tinggi bounding box: 4.44644e+03\n","- confidence (skor kepercayaan deteksi): 3.08422e-01\n","- kelas (label deteksi): 0.00000e+00"],"metadata":{"id":"5rOBVGCLsygf"}},{"cell_type":"markdown","source":["# Let's Play with not detection Images Apply Auto Detect Auto Rotation to every image we have"],"metadata":{"id":"se5nhNj9Ama-"}},{"cell_type":"code","source":["# List to store results for each rotation\n","all_results = []\n","\n","# Define the rotation angles\n","rotation_angles = [0, 90, 180, 270]\n","\n","# Iterate through each image in the folder\n","for filename in ['TB_Fatar.jpg', 'TB_KenzoA.jpg', 'TB_MAlFatih.jpg', 'TB_MeccaShabiraShanum.jpg']: # list foto yang tidak nemu di detect people\n","    if filename.endswith('.jpg'):\n","        # Load the original image\n","        image_path = os.path.join(DATASET_ROOT, filename)\n","        print(f\"File {filename} tidak memiliki deteksi bounding box. Lokasi: {image_path}\")\n","\n","        original_image = cv2.imread(image_path)\n","\n","        # List to store results for each rotation of this image\n","        results_per_rotation = []\n","\n","        # Iterate through each rotation angle\n","        for angle in rotation_angles:\n","            if angle == 90:\n","                # Rotate the image\n","                rotated_image = cv2.rotate(original_image, cv2.ROTATE_90_CLOCKWISE)\n","            elif angle == 180:\n","                # Rotate the image\n","                rotated_image = cv2.rotate(original_image, cv2.ROTATE_180)\n","            elif angle == 270:\n","                # Rotate the image\n","                rotated_image = cv2.rotate(original_image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n","            else:\n","                # Rotate the image for other angles\n","                rotated_image = cv2.rotate(original_image, angle)\n","\n","            # Detect people in the rotated image\n","            detections = detect_people(rotated_image)\n","\n","            # Check if detections is not None and not empty\n","            if detections is not None and len(detections) > 0:\n","                # Iterate through all detected bounding boxes\n","                for detection in detections:\n","                    # Extract bounding box coordinates and confidence\n","                    xmin, ymin, xmax, ymax, confidence, _ = detection[:6]\n","\n","                    # Store the results for this rotation\n","                    results_per_rotation.append({\n","                        'angle': angle,\n","                        'confidence': confidence,\n","                        'roi': (int(xmin), int(ymin), int(xmax), int(ymax)),\n","                        'filename': filename  # Add the filename for reference\n","                    })\n","\n","        # Append results for this image to the overall results\n","        all_results.extend(results_per_rotation)\n","print(\"\\n\")\n","print(f'Hasil BoundingBox In Every Rotation:')\n","for hasil in all_results:\n","  print(hasil)"],"metadata":{"id":"dMTYsVR1HB6v","executionInfo":{"status":"aborted","timestamp":1705381234181,"user_tz":-420,"elapsed":23,"user":{"displayName":"RENDIKA NURHARTANTO","userId":"08654841777874618172"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Main Code"],"metadata":{"id":"G1-cqZ_JPFr3"}},{"cell_type":"code","source":["counter = 0\n","\n","images_with_no_detections = []\n","\n","for jpg_file in jpg_files:\n","    # Construct the full path to the image file\n","    image_path = os.path.join(DATASET_ROOT, jpg_file)\n","\n","    # Read the image using cv2\n","    image = cv2.imread(image_path) # In Matrix Array Form\n","\n","    # Perform your object detection here (I assume you have a `detect_people` function)\n","    detections = detect_people(image) # berupa tensor yang berisi informasi tentang orang yang terdeteksi. Berdasarkan output yang diberikan, tampaknya mencakup koordinat bounding box (x, y, lebar, tinggi), skor kepercayaan (0.308), dan mungkin informasi tambahan.\n","\n","    # If there are detections, take the first one\n","    if len(detections) > 0:\n","        detection = detections[0]  # Take the first detection, Karena takut ada double detection\n","\n","        xmin, ymin, xmax, ymax, confidence, _  = detection[:6] # Akuisisi Komponen dan koordinat hasil deteksi posisi orangnya\n","\n","        # Draw a rectangle around the detected object on the processed image\n","        cv2.rectangle(image, (int(xmin), int(ymin)),\n","                      (int(xmax), int(ymax)), (0, 0, 255), 5) # (0, 0, 255) Warna Hijau BB-nya, dan Width line nya 5 pixel\n","\n","        output_folder_bb = \"/content/drive/MyDrive/Colab Notebooks/Stuntrack/Data Final/BoundingBox Images\"\n","        os.makedirs(output_folder_bb, exist_ok=True)  # Create the folder if it doesn't exist\n","\n","        # Remove \".jpg\" extension from file name\n","        file_names_without_extension = jpg_file.split('.')[0]\n","\n","        output_filename_boundingbox = f\"{output_folder_bb}/{file_names_without_extension}_{counter}_BoundingBox.jpg\" # Generate a unique filename for the processed image\n","\n","        # Save the processed image with the rectangle\n","        cv2.imwrite(output_filename_boundingbox, image) # Menyimpan Gambar yang dikasih BoundingBox\n","\n","        # Crop the detected region of interest (ROI)\n","        roi = image[int(ymin):int(ymax), int(xmin):int(xmax)]\n","\n","        output_folder_crop = \"/content/drive/MyDrive/Colab Notebooks/Stuntrack/Data Final/Cropped Images\"\n","        os.makedirs(output_folder_crop, exist_ok=True)  # Create the folder if it doesn't exist\n","        output_filename_cropped = f\"{output_folder_crop}/{file_names_without_extension}_{counter}_CroppedROI.jpg\" # Generate a unique filename for the processed image\n","\n","        # Save the cropped ROI as a separate image\n","        cv2.imwrite(output_filename_cropped, roi)\n","\n","        # Increment the counter for the next image\n","        counter += 1\n","    else:\n","        images_with_no_detections.append(jpg_file)\n","\n","        # List to store results for each rotation\n","        all_results = []\n","\n","        # Define the rotation angles\n","        rotation_angles = [0, 90, 180, 270]\n","\n","        # Iterate through each image in the folder\n","        angka = 0\n","        for filename in images_with_no_detections:\n","          print(f\"File {filename} Telah Diolah Lebih lanjut pada Iterasi ke-{angka}. Lokasi: {os.path.join(DATASET_ROOT, filename)}\")\n","          if filename.endswith('.jpg'):\n","              # Load the original image\n","              image_path = os.path.join(DATASET_ROOT, filename)\n","\n","              original_image = cv2.imread(image_path)\n","\n","              # List to store results for each rotation of this image\n","              results_per_rotation = []\n","\n","              # Iterate through each rotation angle\n","              for angle in rotation_angles:\n","                  if angle == 90:\n","                      # Rotate the image\n","                      rotated_image = cv2.rotate(original_image, cv2.ROTATE_90_CLOCKWISE)\n","                  elif angle == 180:\n","                      # Rotate the image\n","                      rotated_image = cv2.rotate(original_image, cv2.ROTATE_180)\n","                  elif angle == 270:\n","                      # Rotate the image\n","                      rotated_image = cv2.rotate(original_image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n","                  else:\n","                      # Rotate the image for other angles\n","                      rotated_image = cv2.rotate(original_image, angle)\n","\n","                  # Detect people in the rotated image\n","                  detections = detect_people(rotated_image)\n","\n","                  # Check if detections is not None and not empty\n","                  if detections is not None and len(detections) > 0:\n","                      # Iterate through all detected bounding boxes\n","                      for detection in detections:\n","                          # Extract bounding box coordinates and confidence\n","                          xmin, ymin, xmax, ymax, confidence, _ = detection[:6]\n","\n","                          # Store the results for this rotation\n","                          results_per_rotation.append({\n","                                'angle': angle,\n","                                'confidence': confidence,\n","                                'roi': (int(xmin), int(ymin), int(xmax), int(ymax)),\n","                                'filename': filename  # Add the filename for reference\n","                            })\n","\n","              # Append results for this image to the overall results\n","              all_results.extend(results_per_rotation)\n","          angka += 1\n","\n","print('\\n')\n","print(\"File Perlu Preprocessing agar memunculkan Boundingbox:\")\n","print(images_with_no_detections)\n","print('---'*5)\n","print(f'Hasil BoundingBox In Every Rotation:')\n","for result in all_results:\n","  print(result)\n","\n","from collections import defaultdict\n","\n","# Dictionary to store the highest confidence for each filename\n","highest_confidence_dict = defaultdict(float)\n","\n","# Iterate through all results\n","for result in all_results:\n","  filename = result['filename']\n","  confidence = result['confidence']\n","\n","  # Update highest confidence for this filename\n","  highest_confidence_dict[filename] = max(highest_confidence_dict[filename], confidence)\n","\n","# List to store the final selected results\n","selected_results = []\n","\n","# Iterate through all results again and select the ones with highest confidence\n","for result in all_results:\n","  filename = result['filename']\n","  confidence = result['confidence']\n","\n","  # Check if this result has the highest confidence for its filename\n","  if confidence == highest_confidence_dict[filename]:\n","        selected_results.append(result)\n","\n","# Print the final selected results\n","for result in selected_results:\n","  print(result)"],"metadata":{"id":"ESi5QJEUSgM7","executionInfo":{"status":"aborted","timestamp":1705381234182,"user_tz":-420,"elapsed":24,"user":{"displayName":"RENDIKA NURHARTANTO","userId":"08654841777874618172"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from collections import defaultdict\n","\n","# Dictionary to store the highest confidence for each filename\n","highest_confidence_dict = defaultdict(float)\n","\n","# Iterate through all results\n","for result in all_results:\n","    filename = result['filename']\n","    confidence = result['confidence']\n","\n","    # Update highest confidence for this filename\n","    highest_confidence_dict[filename] = max(highest_confidence_dict[filename], confidence)\n","\n","# List to store the final selected results\n","selected_results = []\n","\n","# Iterate through all results again and select the ones with highest confidence\n","for result in all_results:\n","    filename = result['filename']\n","    confidence = result['confidence']\n","\n","    # Check if this result has the highest confidence for its filename\n","    if confidence == highest_confidence_dict[filename]:\n","        selected_results.append(result)\n","\n","# Print the final selected results\n","for result in selected_results:\n","    print(result)"],"metadata":{"id":"aQVxHLN1O1Ra","executionInfo":{"status":"aborted","timestamp":1705381234184,"user_tz":-420,"elapsed":26,"user":{"displayName":"RENDIKA NURHARTANTO","userId":"08654841777874618172"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Folder to save bounding boxes and cropped images\n","output_folder_crop = \"/content/drive/MyDrive/Colab Notebooks/Stuntrack/Data Final/Cropped Images\"\n","os.makedirs(output_folder_crop, exist_ok=True)\n","output_folder_bb = \"/content/drive/MyDrive/Colab Notebooks/Stuntrack/Data Final/BoundingBox Images\"\n","os.makedirs(output_folder_bb, exist_ok=True)\n","\n","# Iterate through all selected results\n","for result in selected_results:\n","    filename = result['filename']\n","    angle = result['angle']\n","    roi = result['roi']\n","\n","    # Extract bounding box coordinates\n","    xmin, ymin, xmax, ymax = roi\n","\n","    # Draw bounding box on the rotated image\n","    cv2.rectangle(rotated_image, (xmin, ymin), (xmax, ymax), (0, 0, 255), 5)\n","\n","    # Crop the region of interest\n","    cropped_image = rotated_image[ymin:ymax, xmin:xmax]\n","\n","    # Remove \".jpg\" extension from file name\n","    file_names_without_extension = filename.split('.')[0]\n","\n","    # Save the bounding box image\n","    output_path_bbox = os.path.join(output_folder_bb, f\"{file_names_without_extension}_{counter}_BoundingBox_rotate:{angle}.jpg\")\n","    cv2.imwrite(output_path_bbox, rotated_image)\n","\n","    # Save the cropped image\n","    output_path_cropped = os.path.join(output_folder_crop, f\"{file_names_without_extension}_{counter}_CroppedROI_rotate:{angle}.jpg\")\n","    cv2.imwrite(output_path_cropped, cropped_image)"],"metadata":{"id":"iMkIXE_aWhWo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"kkjQCvwJiHMe"},"execution_count":null,"outputs":[]}]}